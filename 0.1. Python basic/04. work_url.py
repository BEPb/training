# python 3.9
# Работа над url адресами записанными в файл URLs.txt, необходимо прочитать файл и посчитать
# распределение тематик новостей (то есть какое количество раз встречается страница с каждой темой).
# Тематикой можно считать первое слово между знаками '/' в URL новости.

#Работа с применением регулярных выражений re

# https://docs.python.org/2/library/re.html#re.compile   - описание библиотеки
import re  # импортируем функцию регулярного выражения

# шаблон страницы новостей (любые символы, потом / и 8 цифр подряд)
# http://www.petefreitag.com/cheatsheets/regex/

pattern = '/.*/'  # создаем шаблон любая последовательность символов от '/' до '/'

prog = re.compile(pattern)  # компилируем шаблон регулярного выражения

# если поставить опцию 'w' при обращении к файлу, то он будет очищен
# если 'a' - данные будут добавлены в конец файла


news = []  # создаю пустой список
with open('URLs.txt', 'r') as f:
    for line in f:
        # убираем символ переноса строки для каждой читаемой строчки
        line = line.strip()


        # если текст строки удовлетворяем регулярному выражению pattern, то выводим строку
        if prog.match(line):
            # print(line)
            tems_news = re.search(r"(?<=/).*?(?=/)", line).group(0)
            # print(tems_news)
            news.append(tems_news)

# print(news)
# set_news = set(news)  # преобразуем в множество уникальные слова
# print(set_news)
# print(news)
my_dict = {i:news.count(i) for i in news}  # используем

print(my_dict)

